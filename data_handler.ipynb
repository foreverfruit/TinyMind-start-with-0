{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 依赖库\n",
    "- numpy\n",
    "- pytorch\n",
    "- opencv-python\n",
    "- PIL\n",
    "- tqdm\n",
    "- pandas\n",
    "安装方式：略，百度，可用pip、conda，由于用到pytorch，需要安装cuda、cudnn，注意版本兼容。\n",
    "本机 win10 + 1050.采用 cuda8.0 + cudnn7.0 并行计算\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 首先看数据处理\n",
    "数据：https://pan.baidu.com/s/1iA-7JCBff1ZE8PGUpVks6w 密码: sewi\n",
    "下载下来是两个压缩包：test1.zip  train.zip\n",
    "解压这两个压缩包，得到两个文件夹（可能存在部分图片解压缩失败，忽略）\n",
    "- test1：测试图片所在目录\n",
    "- train：训练数据集，子目录就是图片的标注—即图片的文字，共100个类x400个单类样本，共计400000个图像组成训练集\n",
    "- label-test1-fake.csv：这是一个结果样例。作用是给出结果的标准格式。每一行是一个测试样本对应的一个结果，一行分为两列，分别是样本文件名，样本文字结果的top5.逗号隔开两列\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 训练集与测试集所在目录\n",
    "sep = os.sep\n",
    "trainpath = 'train'\n",
    "testpath = 'test1'\n",
    "\n",
    "# 训练集是分子目录的，且子目录是类标号，这里得到所有子目录（类别）及其数目\n",
    "categories = os.listdir(trainpath)\n",
    "category_number = len(categories)\n",
    "\n",
    "# 后续用到卷积网络，这里设置图片的大小，之后需要统一将图片都reshape到这个尺寸\n",
    "img_size = (128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**整个数据加载、处理（reshape、merge）都封装到一个函数：trans_data().该函数将训练集数据处理后保存到.npy文件中,\n",
    "在transData内部，遍历整个子目录集合，分别读取子目录中的文件,函数为：load_by_category(category_index)\n",
    "**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_by_category(category_index):\n",
    "    # 目录拼接\n",
    "    path = trainpath + sep + categories[category_index]\n",
    "    # 获取所有该目录（类别）的样本（图片文件）\n",
    "    files = os.listdir(path)\n",
    "    # 结果集\n",
    "    samples = []\n",
    "    # 遍历所有该类样本\n",
    "    for file in files:\n",
    "        # 目录拼接\n",
    "        file = path + sep + file\n",
    "        # 读取图片到np数组\n",
    "        img = np.asarray(Image.open(file))\n",
    "        # 将图片reshape到128*128\n",
    "        img = cv2.resize(img, img_size)\n",
    "        # 加入结果集\n",
    "        samples.append(img)\n",
    "    samples = np.array(samples)\n",
    "    # 类标号：每一幅图片的结果都是一个长度为category_number的结果向量\n",
    "    labels = np.zeros([len(samples), category_number], dtype=np.uint8)\n",
    "    # 当前labels的类标号设置为1，通过位置确定类\n",
    "    # 可以想象最后将所有的category的labels拼接起来应该是一个阶梯矩阵\n",
    "    labels[:, category_index] = 1\n",
    "    return samples, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trans_data():\n",
    "    # 创建一个空的n*128*128的数据集合,第一维表示样本索引，第二三维128*128表示数据\n",
    "    # 这里*img_size是列表的元素解包，这样[-1,*img_size]等于[-1,128,128]，而不是[-1,(128,128)]\n",
    "    all_samples = np.zeros([0, *img_size], dtype=np.uint8)\n",
    "    # 创建一个空的n*100的结果（类标号）集合，第一维表示样本index，100表示该样本属于这100个类别的概率（训练集上是1和0）\n",
    "    labels = np.reshape(np.array([], dtype=np.uint8), [0, category_number])\n",
    "    # 遍历所有训练集子目录（类别），这里tqdm是一个可视化进度条的库\n",
    "    for index in tqdm(range(category_number)):\n",
    "        # 获取某一个类别的数据和标注\n",
    "        data, label = load_by_category(index)\n",
    "        # 将结果合并到最终结果集中\n",
    "        all_samples = np.append(all_samples, data, axis=0)\n",
    "        labels = np.append(labels, label, axis=0)\n",
    "    # 保存数据\n",
    "    np.save('data.npy', all_samples)\n",
    "    np.save('label.npy', labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**对数据处理过程最好的理解，是看数据的维度（shape）**\n",
    "\n",
    "这里补充tqdm库的简要说明\n",
    "> Tqdm 是一个快速，可扩展的Python进度条，可以在 Python 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 tqdm(iterator)。\n",
    "\n",
    "\n",
    "```python\n",
    "from tqdm import tqdm  \n",
    "# 基本用法\n",
    "for i in tqdm(range(10000)):  \n",
    "    sleep(0.01)  \n",
    "\n",
    "# trange用法,trange（i）是tqdm（i）的一个特殊实例\n",
    "for i in trange(100):  \n",
    "        sleep(0.1)  \n",
    "\n",
    "# 只要传入可迭代iterator的对象都可以\n",
    "pbar = tqdm([\"a\", \"b\", \"c\", \"d\"])  \n",
    "for char in pbar:  \n",
    "    pbar.set_description(\"Processing %s\" % char) \n",
    "\n",
    "# 也可手动更新\n",
    "with tqdm(total=100) as pbar:  \n",
    "    for i in range(10):  \n",
    "        pbar.update(10) \n",
    "\n",
    "# 手动更新\n",
    "pbar = tqdm(total=100)  \n",
    "for i in range(10):  \n",
    "    pbar.update(10)  \n",
    "pbar.close()          \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**至此，数据处理部分就算算完成了，之后做两个工作**\n",
    "- 测试上述过程\n",
    "- 为外部提供一个数据集相关的接口。即让其他py模块只处理它的逻辑，需要用到数据，就从本py脚本中调用接口得到数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 对外提供一个加载测试集的函数，在应用模型测试的时候调用该方法\n",
    "def load_test_data():\n",
    "    files = os.listdir(testpath)\n",
    "    test_data_set = []\n",
    "    for file in tqdm(files):\n",
    "        file = testpath + sep + file\n",
    "        img = np.asarray(Image.open(file))\n",
    "        img = cv2.resize(img, img_size)\n",
    "        test_data_set.append(img)\n",
    "    test_data_set = np.array(test_data_set)\n",
    "    return test_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(39999, 128, 128) (39999, 100)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████| 10000/10000 [00:07<00:00, 1358.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 128, 128)\n"
     ]
    }
   ],
   "source": [
    "# 读取之前保存的文件，检查shape，看看是不是预期的，我这里样本数是39999，少了一个，有张图解压缩的时候出错了\n",
    "if __name__ == '__main__':\n",
    "    # trans_data()\n",
    "    train_data = np.load('data.npy')\n",
    "    train_labels = np.load('label.npy')\n",
    "    print(train_data.shape, train_labels.shape)\n",
    "    test_data = load_test_data()\n",
    "    print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 向外提供的数据接口——TrainSet类\n",
    "- TrainSet类的父类是Torch的一种抽象类，表示一个数据集。torch.utils.data.Dataset。继承该类需要实现其两个抽象方法（An abstract class representing a Dataset.All other datasets should subclass it. All subclasses should override``__len__``, that provides the size of the dataset, and ``__getitem__``, supporting integer indexing in range from 0 to len(self) exclusive.）\n",
    "- TrainSet的构造方法中，读取“data.npy”“label.npy”分别获取全部的data和label。但每次使用的并不是全部数据训练，而是打乱之后的"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
